# global configs
Global:
  checkpoints: null
  pretrained_model: null
  output_dir: "./output/"
  device: "gpu"
  save_interval: 1
  eval_during_train: True
  eval_interval: 1
  epochs: 28
  print_batch_step: 10
  use_visualdl: False
  # used for static mode and model export
  image_shape: [3, 112, 112]
  save_inference_dir: "./inference"
  eval_mode: "adaface"

# model architecture
Arch:
  name: "RecModel"
  infer_output_key: "features"
  infer_add_softmax: False
  Backbone:
    name: "MobileFaceNet_128"
    num_features: 512
  Head:
    name: "AdaMargin"
    embedding_size: 512
    class_num: 10572
    m: 0.4
    s: 64
    h: 0.333
    t_alpha: 0.01

# loss function config for traing/eval process
Loss:
  Train:
    - CELoss:
        weight: 1.0

Optimizer:
  name: Momentum
  momentum: 0.9
  lr:
    name: Piecewise
    learning_rate: 0.1
    decay_epochs: [10, 16, 22]
    values: [0.1, 0.01, 0.001, 0.0001]
  regularizer:
    name: 'L2'
    coeff: 0.0005

# data loader for train and eval
DataLoader:
  Train:
    dataset:
        name: "AdaFaceDataset"
        root: "./dataset/face_webface_112x112/faces_webface_112x112/imgs"
        transform:
          - CropWithPadding:
              prob: 0.2
              padding_num: 0
              size: [112, 112]
              scale: [0.2, 1.0]
              ratio: [0.75, 1.3333333333333333]
          - RandomInterpolationAugment:
              prob: 0.2
          - ColorJitter:
              prob: 0.2
              brightness: 0.5
              contrast: 0.5
              saturation: 0.5
              hue: 0
          - RandomHorizontalFlip:
          - ToTensor:
          - Normalize:
              mean: [0.5, 0.5, 0.5]
              std: [0.5, 0.5, 0.5]
    sampler:
        name: DistributedBatchSampler
        batch_size: 512
        drop_last: False
        shuffle: True
    loader:
        num_workers: 6
        use_shared_memory: True

  Eval:
    dataset:
      name: FiveValidationDataset
      val_data_path: ./dataset/face_webface_112x112/faces_webface_112x112
    sampler:
        name: BatchSampler
        batch_size: 256
        drop_last: False
        shuffle: True
    loader:
        num_workers: 6
        use_shared_memory: True
Metric:
  Train:
    - TopkAcc:
        topk: [1, 5]